{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from seq2seq.data import Dataset\n",
    "from seq2seq.model import Seq2seqModel\n",
    "from seq2seq.train import Trainer, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_ID = 1\n",
    "device = torch.device(\"cuda:{}\".format(GPU_ID)) if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_FILE_PATH = 'smart_mobile/smart_src_khaiii.txt'\n",
    "TGT_FILE_PATH = 'smart_mobile/smart_tgt_khaiii.txt'\n",
    "\n",
    "EXPR_PATH = 'smart_mobile/'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "MAX_SRC_LEN = 10\n",
    "MAX_TGT_LEN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 90729 sentence pairs\n",
      "\n",
      "Trim data to 20074 sentence pairs\n",
      "Avg length of src :  7.272591411776427\n",
      "Avg length of tgt :  7.307063863704294\n",
      "\n",
      "Source vocab : 5062 (0 reduced)\n",
      "Target vocab : 5060 (0 reduced)\n",
      "\n",
      "Success to preprocess data!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(\n",
    "    src_file_path=SRC_FILE_PATH,\n",
    "    tgt_file_path=TGT_FILE_PATH,\n",
    "    max_src_len=MAX_SRC_LEN,\n",
    "    max_tgt_len=MAX_TGT_LEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LAYERS = 1\n",
    "INPUT_SIZE = dataset.src_vocab_size\n",
    "EMBED_SIZE = 64\n",
    "HIDDEN_SIZE = 64\n",
    "OUTPUT_SIZE = dataset.tgt_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2seqModel(\n",
    "    n_layers=NUM_LAYERS,\n",
    "    input_size=INPUT_SIZE,\n",
    "    emb_size=EMBED_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    output_size=OUTPUT_SIZE,\n",
    "    max_tgt_len=MAX_TGT_LEN,\n",
    "    dropout_p=0.0,\n",
    "    bi_encoder=True,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    device=device,\n",
    "    print_interval=1,\n",
    "    plot_interval=-1,\n",
    "    checkpoint_interval=10,\n",
    "    expr_path=EXPR_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to train\n",
      "epoch:  1 ( 10%) time:    0m 21s (-      3m 9s) loss:2219.0129\n",
      "epoch:  2 ( 20%) time:    0m 42s (-     2m 51s) loss:1658.9459\n",
      "epoch:  3 ( 30%) time:     1m 3s (-     2m 28s) loss:1488.8841\n",
      "epoch:  4 ( 40%) time:    1m 23s (-      2m 4s) loss:1375.5662\n",
      "epoch:  5 ( 50%) time:    1m 44s (-     1m 44s) loss:1285.6540\n",
      "epoch:  6 ( 60%) time:     2m 4s (-     1m 23s) loss:1208.4589\n",
      "epoch:  7 ( 70%) time:    2m 25s (-      1m 2s) loss:1139.2452\n",
      "epoch:  8 ( 80%) time:    2m 45s (-     0m 41s) loss:1075.5966\n",
      "epoch:  9 ( 90%) time:     3m 7s (-     0m 20s) loss:1016.1490\n",
      "epoch: 10 (100%) time:    3m 27s (-      0m 0s) loss:960.6209\n"
     ]
    }
   ],
   "source": [
    "trainer.train(num_epoch=10, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(dataset, model, device=device)\n",
    "evaluator.loadModel(EXPR_PATH+'ep10.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : 국제 전화 요 ? <EOS>\n",
      "Gen   : 물론 이 ㅂ니다 . <EOS>\n",
      "\n",
      "Input : 오전 7 시 부터 이 ㅂ니다 . <EOS>\n",
      "Gen   : 알 겠 습니다 . <EOS>\n",
      "\n",
      "Input : 따로 예약 을 안 하 시 었 나요 ? <EOS>\n",
      "Gen   : 아니 요 . <EOS>\n",
      "\n",
      "Input : 15 $ 입 니 다 . <EOS>\n",
      "Gen   : 알 겠 습니다 . <EOS>\n",
      "\n",
      "Input : 알 겠 습니다 . <EOS>\n",
      "Gen   : 즐겁 ㄴ 여행 되 시 어요 . <EOS>\n",
      "\n",
      "Input : 잘 되 었 네요 . 감사 하 ㅂ니다 . <EOS>\n",
      "Gen   : 즐겁 ㄴ 여행 되 시 어요 . <EOS>\n",
      "\n",
      "Input : 그렇 군요 , 감사 하 ㅂ니다 . <EOS>\n",
      "Gen   : 천 만에 요 . <EOS>\n",
      "\n",
      "Input : 무엇 을 돕 아 드리 ㄹ까요 ? <EOS>\n",
      "Gen   : 음식 이 잘못 나오 았 나요 ? <EOS>\n",
      "\n",
      "Input : 유튜브 동영상 보 시 었 어요 ? <EOS>\n",
      "Gen   : 네 , 맞 습니다 . <EOS>\n",
      "\n",
      "Input : 네 . 덕분 에 . <EOS>\n",
      "Gen   : 감사 하 ㅂ니다 . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pairs, attn_list = evaluator.evalModel(num=10, beam_size=5)\n",
    "for p, attn in zip(pairs, attn_list):\n",
    "    print('Input : ' + ' '.join(p[0]))\n",
    "    print('Gen   : ' + ' '.join(p[1]))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
