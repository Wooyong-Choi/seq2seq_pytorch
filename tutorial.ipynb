{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from seq2seq.dataset import Dataset\n",
    "from seq2seq.model import Seq2seqModel\n",
    "from seq2seq.trainer import Trainer, Evaluator\n",
    "from seq2seq.utils.Visualization import vizAttn, vizAccumAttn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "GPU_ID = 1\n",
    "USE_CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_FILE_PATH = 'toy_data/toy_src_data.txt'\n",
    "TGT_FILE_PATH = 'toy_data/toy_tgt_data.txt'\n",
    "\n",
    "EXPR_PATH = 'toy_data/'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "MAX_SRC_LEN = 10\n",
    "MAX_TGT_LEN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 1000 sentence pairs\n",
      "\n",
      "Trim data to 1000 sentence pairs\n",
      "Avg length of src :  5.441\n",
      "Avg length of tgt :  5.441\n",
      "\n",
      "Source vocab : 54 (0 reduced)\n",
      "Target vocab : 54 (0 reduced)\n",
      "\n",
      "Success to preprocess data!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(\n",
    "    src_file_path=SRC_FILE_PATH,\n",
    "    tgt_file_path=TGT_FILE_PATH,\n",
    "    max_src_len=MAX_SRC_LEN,\n",
    "    max_tgt_len=MAX_TGT_LEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = dataset.src_vocab_size\n",
    "EMBED_SIZE = 64\n",
    "HIDDEN_SIZE = 64\n",
    "OUTPUT_SIZE = dataset.tgt_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2seqModel(\n",
    "    name='test_model',\n",
    "    input_size=INPUT_SIZE,\n",
    "    emb_size=EMBED_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    output_size=OUTPUT_SIZE,\n",
    "    max_src_len=MAX_SRC_LEN,\n",
    "    max_tgt_len=MAX_TGT_LEN,\n",
    "    dropout_p=0.2,\n",
    "    bidirectional=True,\n",
    "    use_attention=True,\n",
    "    gpu_id=GPU_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, dataset, gpu_id=GPU_ID, print_interval=1, plot_interval=1, checkpoint_interval=10, expr_path=EXPR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to train\n",
      "epoch:  1 ( 10%) time:     0m 1s (-      0m 9s) loss:109.3446\n"
     ]
    }
   ],
   "source": [
    "trainer.train(num_epoch=10, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(dataset, model)\n",
    "evaluator.loadModel(EXPR_PATH+'test_model10.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pairs, attn_list = evaluator.evalModel(num=3, beam_size=5)\n",
    "for p, attn in zip(pairs, attn_list):\n",
    "    print('Input : ' + ' '.join(p[0]))\n",
    "    print('Gen   : ' + ' '.join(p[1]))\n",
    "    vizAttn(p[0], p[1], attn)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
