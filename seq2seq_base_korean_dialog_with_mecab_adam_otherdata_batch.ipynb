{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import operator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from konlpy.tag import Twitter\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.0_2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "USE_CUDA = True\n",
    "GPU_ID = 3\n",
    "\n",
    "print(USE_CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SYMBOL = 4\n",
    "\n",
    "PAD_TOK = '<PAD>'\n",
    "SOS_TOK = '<SOS>'\n",
    "EOS_TOK = '<EOS>'\n",
    "UNK_TOK = '<UNK>'\n",
    "\n",
    "PAD_IDX = 0\n",
    "SOS_IDX = 1\n",
    "EOS_IDX = 2\n",
    "UNK_IDX = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_VOCAB_SIZE = 5000\n",
    "TGT_VOCAB_SIZE = 5000\n",
    "\n",
    "MAX_LENGTH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_FILENAME = 'dataset/korean_dialog/hangul_src.txt'\n",
    "TGT_FILENAME = 'dataset/korean_dialog/hangul_tgt.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {\n",
    "            SOS_IDX:SOS_TOK,\n",
    "            EOS_IDX:EOS_TOK,\n",
    "            PAD_IDX:PAD_TOK,\n",
    "            UNK_IDX:UNK_TOK\n",
    "        }\n",
    "        self.n_words = len(self.index2word)\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence:\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2count:\n",
    "            self.word2count[word] = 1\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "    def makeVocabDict(self, vocab_size):\n",
    "        sorted_vocab = sorted(self.word2count.items(), key=operator.itemgetter(1), reverse=True)[:vocab_size]\n",
    "        \n",
    "        sorted_i2w = {i+NUM_SYMBOL:sorted_vocab[i][0] for i in range(vocab_size)}\n",
    "        sorted_w2i = {sorted_vocab[i][0]:i for i in range(vocab_size)}\n",
    "        \n",
    "        self.index2word.update(sorted_i2w)\n",
    "        self.word2index.update(sorted_w2i)\n",
    "        \n",
    "        self.n_words = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    s = re.sub('[^가-힝0-9a-zA-Z\\\\s]', '', s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(src_fileName, tgt_fileName, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    src_lines = open(src_fileName, 'r', encoding='utf-8').readlines()\n",
    "    tgt_lines = open(tgt_fileName, 'r', encoding='utf-8').readlines()\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(src_lines[i][:-1]), normalizeString(tgt_lines[i][:-1])] for i in range(len(src_lines))]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_data = Data()\n",
    "        output_data = Data()\n",
    "    else:\n",
    "        input_data = Data()\n",
    "        output_data = Data()\n",
    "\n",
    "    print(\"Success!\")\n",
    "    \n",
    "    return input_data, output_data, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPair(p):\n",
    "    return len(p[0]) < MAX_LENGTH and \\\n",
    "        len(p[1]) < MAX_LENGTH\n",
    "    \n",
    "def filterPairs(pairs, tagger=Twitter()):\n",
    "    pairs = [[tagger.morphs(pair[0]), tagger.morphs(pair[1])] for pair in pairs]\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(src_fileName, tgt_fileName, reverse=False):\n",
    "    input_data, output_data, pairs = readData(src_fileName, tgt_fileName)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_data.addSentence(pair[0])\n",
    "        output_data.addSentence(pair[1])\n",
    "        \n",
    "    org_input_n_words = input_data.n_words\n",
    "    org_output_n_words = output_data.n_words\n",
    "        \n",
    "    input_data.makeVocabDict(SRC_VOCAB_SIZE)\n",
    "    output_data.makeVocabDict(TGT_VOCAB_SIZE)    \n",
    "    \n",
    "    print(\"Num of reduced words :\")\n",
    "    print(\"- Input data  :\", org_input_n_words - input_data.n_words)\n",
    "    print(\"- Output data :\", org_output_n_words - output_data.n_words)\n",
    "    \n",
    "    return input_data, output_data, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(data, sentence):\n",
    "    return [data.word2index[word] if word in data.word2index else UNK_IDX for word in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paddingSeqIndexes(seq):\n",
    "    pad_num = MAX_LENGTH - len(seq)\n",
    "    return seq + [PAD_IDX]*pad_num\n",
    "\n",
    "def variableFromSentence(data, sentence, isPadding=False):\n",
    "    indexes = indexesFromSentence(data, sentence)\n",
    "    indexes.append(EOS_IDX)\n",
    "    \n",
    "    if isPadding:\n",
    "        indexes = paddingSeqIndexes(indexes)\n",
    "    \n",
    "    #result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    result = Variable(torch.LongTensor(indexes))\n",
    "    if USE_CUDA:\n",
    "        return result.cuda(GPU_ID)\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variablesFromBatch(batch):\n",
    "    input_batch = []\n",
    "    target_batch = []\n",
    "    for pair in batch:\n",
    "        input_batch.append(variableFromSentence(input_data,pair[0], isPadding=True))\n",
    "        target_batch.append(variableFromSentence(output_data, pair[1], isPadding=True))\n",
    "        \n",
    "    if USE_CUDA:\n",
    "        return (torch.stack(input_batch, dim=0).cuda(GPU_ID), torch.stack(target_batch, dim=0).cuda(GPU_ID))\n",
    "    else:\n",
    "        return (torch.stack(input_batch, dim=0), torch.stack(target_batch, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Success!\n",
      "Read 92192 sentence pairs\n",
      "Trimmed to 87099 sentence pairs\n",
      "Counting words...\n",
      "Num of reduced words :\n",
      "- Input data  : 13799\n",
      "- Output data : 13806\n"
     ]
    }
   ],
   "source": [
    "input_data, output_data, pairs = prepareData(SRC_FILENAME, TGT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(pairs)*0.8)\n",
    "val_size = int(len(pairs)*0.1)\n",
    "test_size = int(len(pairs)*0.1)\n",
    "\n",
    "train_pairs = pairs[:train_size]\n",
    "val_pairs = pairs[train_size:train_size+val_size]\n",
    "test_pairs = pairs[train_size+val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBatch(data=train_pairs, batch_size=128):\n",
    "    num = len(data)\n",
    "    for idx in range(0, num, batch_size):\n",
    "        batch = data[idx:min(idx + batch_size, num)]\n",
    "        batch = sorted(batch, key=lambda x: len(x[0]), reverse=True)\n",
    "        batch_len = [len(d[0]) for d in batch]\n",
    "        yield (batch, batch_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = input_data.n_words  # Num of Words\n",
    "HIDDEN_SIZE = 256  # Embedding Dimension\n",
    "OUTPUT_SIZE = output_data.n_words\n",
    "\n",
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size, padding_idx=0)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input_seqs, input_lens, hidden):\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        packed = pack_padded_sequence(embedded, input_lens, batch_first=True)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, output_lengths = pad_packed_sequence(outputs, batch_first=True)\n",
    "        return outputs, hidden\n",
    "\n",
    "    def initHidden(self, cur_batch_size):\n",
    "        result = Variable(torch.zeros(self.n_layers, cur_batch_size, self.hidden_size))\n",
    "        if USE_CUDA:\n",
    "            return result.cuda(GPU_ID)\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "    def forward_step(self, input_var, hidden, cur_batch_size):\n",
    "        embedded  = self.embedding(input_var)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        output = self.out(output.view(-1, self.hidden_size))\n",
    "        output = self.softmax(output)\n",
    "        output = output.view(cur_batch_size, self.output_size, -1)\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def forward(self, inputs, hidden, cur_batch_size):        \n",
    "        decoder_outputs = []\n",
    "        sequence_symbols = []\n",
    "        #lengths = np.array([max_length] * batch_size)\n",
    "        \n",
    "        def decode(step, step_output):\n",
    "            decoder_outputs.append(step_output)\n",
    "            symbols = decoder_outputs[-1].topk(1)[1]\n",
    "            sequence_symbols.append(symbols)\n",
    "            return symbols\n",
    "        \n",
    "        decoder_input = inputs[:, 0].unsqueeze(1)\n",
    "        for di in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden = self.forward_step(decoder_input, hidden, cur_batch_size)\n",
    "            step_output = decoder_output.squeeze(2)\n",
    "            symbols = decode(di, step_output)\n",
    "            decoder_input = symbols\n",
    "        \n",
    "        sequence_symbols = torch.stack(sequence_symbols, dim=1).squeeze(2)\n",
    "        decoder_outputs = torch.stack(decoder_outputs, dim=0)\n",
    "        \n",
    "        return decoder_outputs, decoder_hidden, sequence_symbols\n",
    "\n",
    "    def initHidden(self, encoder_hidden):\n",
    "        result = Variable(torch.zeros(1, BATCH_SIZE, self.hidden_size))\n",
    "        if USE_CUDA:\n",
    "            return result.cuda(GPU_ID)\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, input_lengths, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "          criterion, max_length=MAX_LENGTH):\n",
    "    cur_batch_size = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden(cur_batch_size)\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda(GPU_ID) if USE_CUDA else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, input_lengths, encoder_hidden)\n",
    "\n",
    "    decoder_input = target_variable\n",
    "    decoder_input = decoder_input.cuda(GPU_ID) if USE_CUDA else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoder_outputs, decoder_hidden, generated_sequence = decoder(decoder_input, decoder_hidden, cur_batch_size)\n",
    "\n",
    "    for step, step_output in enumerate(decoder_outputs):\n",
    "        loss += criterion(step_output, target_variable[:, step])\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEpochs(encoder, decoder, n_epoch, print_every=1, plot_every=1, learning_rate=1e-3, w_decay=1e-5):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate, weight_decay=w_decay)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss(size_average=True)\n",
    "\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        for batch, batch_len in getBatch(batch_size=BATCH_SIZE):\n",
    "            input_variable, target_variable = variablesFromBatch(batch)\n",
    "    \n",
    "            loss = train(input_variable, batch_len, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "    \n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epoch),\n",
    "                                            epoch, epoch / n_epoch * 100, print_loss_avg))\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "        \n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleResponce(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=5):\n",
    "    input_variable = variableFromSentence(input_data, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden(1)\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda(GPU_ID) if USE_CUDA else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], [input_length], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "        \n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    score_board = [[[SOS_IDX], 0]]  #  list of [[sequence] and score]\n",
    "    \n",
    "    # with beam search\n",
    "    while len(score_board[0][0]) != max_length + 1:\n",
    "        # Select each candidate\n",
    "        for cur, cur_score in score_board: # [[sequence], score].\n",
    "            candidate = cur[-1]\n",
    "        \n",
    "            # Find beams\n",
    "            decoder_input = Variable(torch.LongTensor([[candidate]]))\n",
    "            decoder_input = decoder_input.cuda(GPU_ID) if USE_CUDA else decoder_input\n",
    "        \n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topVecs, topIdxs = decoder_output.data.topk(beam_size)\n",
    "        \n",
    "            for next, next_score in zip(topIdxs.tolist()[0], topVecs.tolist()[0]):\n",
    "                # Append beams to score board\n",
    "                score = cur_score + next_score  # log softmax\n",
    "                score_board.append([cur+[next], score])\n",
    "            \n",
    "        # select top 5\n",
    "        score_board = sorted(score_board, key=operator.itemgetter(1), reverse=True)[:5]\n",
    "\n",
    "    decoded_words = []\n",
    "    \n",
    "    for idx in score_board[0][0]:\n",
    "        if idx == EOS_IDX:\n",
    "            decoded_words.append(EOS_TOK)\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_data.index2word[idx])\n",
    "\n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleResponces(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = sampleResponces(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(INPUT_SIZE, HIDDEN_SIZE)\n",
    "decoder = DecoderRNN(HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "if USE_CUDA:\n",
    "    encoder.cuda(GPU_ID)\n",
    "    decoder.cuda(GPU_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31m 49s (- 1559m 16s) (10 2%) 8493.7286\n",
      "64m 7s (- 1539m 11s) (20 4%) 7877.0970\n",
      "98m 30s (- 1543m 16s) (30 6%) 7510.1371\n",
      "131m 9s (- 1508m 24s) (40 8%) 7188.4905\n"
     ]
    }
   ],
   "source": [
    "trainEpochs(encoder, decoder, NUM_EPOCH, print_every=10, plot_every=5, learning_rate=1e-3, w_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), 'encoder.model')\n",
    "torch.save(decoder.state_dict(), 'decoder.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "\n",
    "def evalModel(encoder, decoder):\n",
    "    \n",
    "    loss = 0\n",
    "\n",
    "    criterion = nn.NLLLoss(size_average=True)\n",
    "\n",
    "    for batch, batch_len in getBatch(data=test_pairs, batch_size=BATCH_SIZE):\n",
    "        input_variable, target_variable = variablesFromBatch(batch)\n",
    "    \n",
    "        cur_batch_size = input_variable.size()[0]\n",
    "        encoder_hidden = encoder.initHidden(cur_batch_size)\n",
    "        \n",
    "        target_length = target_variable.size()[0]\n",
    "        \n",
    "        encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n",
    "        encoder_outputs = encoder_outputs.cuda(GPU_ID) if USE_CUDA else encoder_outputs\n",
    "        \n",
    "        encoder_outputs, encoder_hidden = encoder(input_variable, batch_len, encoder_hidden)\n",
    "        \n",
    "        decoder_input = target_variable\n",
    "        decoder_input = decoder_input.cuda(GPU_ID) if USE_CUDA else decoder_input\n",
    "        \n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs, decoder_hidden, generated_sequence = decoder(decoder_input, decoder_hidden, cur_batch_size)\n",
    "        \n",
    "        for step, step_output in enumerate(decoder_outputs):\n",
    "            loss += criterion(step_output, target_variable[:, step]).data[0]/cur_batch_size\n",
    "        \n",
    "    print('loss = ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalModel(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for test_pair in getBatch(data=train_pairs, batch_size=128):\n",
    "    print(\"input  : \", test_pair[0])\n",
    "    print(\"output : \", evaluate(encoder, decoder, test_pair[0]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    input_sentence = input()\n",
    "    print(\"output : \", evaluate(encoder, decoder, input_sentence))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
