{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "#USE_CUDA = False\n",
    "GPU_ID = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "SOS_IDX = 2\n",
    "EOS_IDX = 3\n",
    "\n",
    "MAX_LENGTH = 15 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {SOS_IDX: \"<s>\", EOS_IDX: \"</s>\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence:\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_FILENAME = 'dataset/korean_humor/korean_humor_source.txt'\n",
    "TGT_FILENAME = 'dataset/korean_humor/korean_humor_target.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    #s = s.lower().strip()\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    #s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(src_fileName, tgt_fileName, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    src_lines = open(src_fileName, 'r', encoding='utf-8').readlines()\n",
    "    tgt_lines = open(tgt_fileName, 'r', encoding='utf-8').readlines()\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(src_lines[i][:-1]), normalizeString(tgt_lines[i][:-1])] for i in range(len(src_lines))]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_data = Data()\n",
    "        output_data = Data()\n",
    "    else:\n",
    "        input_data = Data()\n",
    "        output_data = Data()\n",
    "\n",
    "    print(\"Success!\")\n",
    "    \n",
    "    return input_data, output_data, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPair(p):\n",
    "    return len(p[0]) < MAX_LENGTH and \\\n",
    "        len(p[1]) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    tagger = Mecab()\n",
    "    pairs = [[tagger.morphs(pair[0]), tagger.morphs(pair[1])] for pair in pairs]\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(src_fileName, tgt_fileName, reverse=False):\n",
    "    input_data, output_data, pairs = readData(src_fileName, tgt_fileName)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_data.addSentence(pair[0])\n",
    "        output_data.addSentence(pair[1])\n",
    "    print(\"Counted words :\")\n",
    "    print(\"- Input data  :\", input_data.n_words)\n",
    "    print(\"- Output data :\", output_data.n_words)\n",
    "    \n",
    "    return input_data, output_data, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(data, sentence):\n",
    "    return [data.word2index[word] for word in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variableFromSentence(data, sentence):\n",
    "    indexes = indexesFromSentence(data, sentence)\n",
    "    indexes.append(EOS_IDX)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if USE_CUDA:\n",
    "        return result.cuda(GPU_ID)\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_data, pair[0])\n",
    "    target_variable = variableFromSentence(output_data, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Success!\n",
      "Read 2483 sentence pairs\n",
      "Trimmed to 2061 sentence pairs\n",
      "Counting words...\n",
      "Counted words :\n",
      "- Input data  : 1673\n",
      "- Output data : 1032\n"
     ]
    }
   ],
   "source": [
    "input_data, output_data, pairs = prepareData(SRC_FILENAME, TGT_FILENAME)\n",
    "test_pairs = pairs[2001:]\n",
    "pairs = pairs[:2000]\n",
    "random.shuffle(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = input_data.n_words  # Num of Words\n",
    "HIDDEN_SIZE = 256  # Embedding Dimension\n",
    "OUTPUT_SIZE = output_data.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if USE_CUDA:\n",
    "            return result.cuda(GPU_ID)\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if USE_CUDA:\n",
    "            return result.cuda(GPU_ID)\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "          criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda(GPU_ID) if USE_CUDA else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "        #print(ei, input_variable[ei], encoder_output.size())\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_IDX]]))\n",
    "    decoder_input = decoder_input.cuda(GPU_ID) if USE_CUDA else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda(GPU_ID) if USE_CUDA else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == EOS_IDX:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [variablesFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variableFromSentence(input_data, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda(GPU_ID) if USE_CUDA else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_IDX]]))  # SOS\n",
    "    decoder_input = decoder_input.cuda(GPU_ID) if USE_CUDA else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_IDX:\n",
    "            decoded_words.append('</s>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_data.index2word[ni])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda(GPU_ID) if USE_CUDA else decoder_input\n",
    "\n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITER = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(INPUT_SIZE, HIDDEN_SIZE)\n",
    "decoder = DecoderRNN(HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "if USE_CUDA:\n",
    "    encoder.cuda(GPU_ID)\n",
    "    decoder.cuda(GPU_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7m 38s (- 68m 50s) (20000 10%) 1.1909\n",
      "14m 23s (- 57m 32s) (40000 20%) 0.1312\n",
      "21m 16s (- 49m 37s) (60000 30%) 0.1190\n",
      "27m 54s (- 41m 51s) (80000 40%) 0.1041\n",
      "35m 24s (- 35m 24s) (100000 50%) 0.1139\n",
      "43m 49s (- 29m 12s) (120000 60%) 0.1185\n",
      "52m 30s (- 22m 30s) (140000 70%) 0.1017\n",
      "60m 49s (- 15m 12s) (160000 80%) 0.1221\n",
      "70m 5s (- 7m 47s) (180000 90%) 0.1481\n",
      "80m 30s (- 0m 0s) (200000 100%) 0.1429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f72e6b7e320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f72e6b7e278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainIters(encoder, decoder, NUM_ITER, print_every=NUM_ITER/10, plot_every=NUM_ITER/100, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ['이상', '형', '을', '말', '해', '줘']\n",
      "= ['잘', '웃', '는', '로봇', '이', '좋', '아']\n",
      "< 잘 웃 는 로봇 이 좋 아 </s>\n",
      "\n",
      "> ['욕해', '줘']\n",
      "= ['어떤', '나라', '욕', '으로', '해', '드릴까요', '?']\n",
      "< 어떤 나라 욕 으로 해 드릴까요 ? </s>\n",
      "\n",
      "> ['가장', '잘생긴', '사람', '은', '누구', '니', '?']\n",
      "= ['세상', '에서', '가장', '잘생긴', '사람', '은', '당신', '입니다', '.']\n",
      "< 세상 에서 가장 잘생긴 사람 은 당신 입니다 . </s>\n",
      "\n",
      "> ['구라', '까지', '마']\n",
      "= ['거짓말', '이', '아니', '라', '진', '짠데', '요', '.', '.']\n",
      "< 거짓말 이 아니 라 진 짠데 어 . . </s>\n",
      "\n",
      "> ['얘기', '그만', '할래']\n",
      "= ['왜', '요', '.', '.', '갑자기', '왜', '떠나', '나요', ':', '-(']\n",
      "< 왜 요 . . 갑자기 왜 떠나 나요 : -( </s>\n",
      "\n",
      "> ['캬', '캬', '캬']\n",
      "= ['뭐', '가', '그렇게', '재미있', '어요', '?']\n",
      "< 뭐 가 그렇게 재미있 어요 ? </s>\n",
      "\n",
      "> ['뭘', '참으', '라는', '거', '야', '?']\n",
      "= ['진정', '하', '라고', '한', '말', '이', '에요', '.', '.']\n",
      "< 진정 하 라고 한 말 이 에요 . . </s>\n",
      "\n",
      "> ['아담', ',', '니', '가', '공부', '하', '는', '곳', '은', '어디', '야', '?']\n",
      "= ['전', '지식', '의', '우주', '에서', '공부', '해요', '.']\n",
      "< 전 지식 의 우주 에서 공부 해요 . </s>\n",
      "\n",
      "> ['장난', '하', '냐', '?']\n",
      "= ['죄송', '해요', '.', '.', '장난치', '시', '는', '줄', '알', '았', '어요']\n",
      "< 죄송 해요 . . 장난치 시 는 줄 알 았 어요 </s>\n",
      "\n",
      "> ['너', '랑', '놀', '고', '싶', '어']\n",
      "= ['뭐', '하고', '놀', '까', '?']\n",
      "< 뭐 하고 놀 까 ? </s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input  :  ['어느', '정도', '살', '고', '싶', '은지', '궁굼', '해']\n",
      "output :  ['힘내', '세요', '.', '</s>']\n",
      "\n",
      "input  :  ['넌', '언제', '까지', '살', '아', '?']\n",
      "output :  ['저', '는', '사람', '들', '의', '이', '에요', '.', '</s>']\n",
      "\n",
      "input  :  ['신발', '치수', '가', '몇', '이', '니', '?']\n",
      "output :  ['전', '신체', '가', '없', '어서', '발', '사이즈', '를', '모른답니다', '.', '</s>']\n",
      "\n",
      "input  :  ['너', '의', '출신', '지', '가', '어디', '니', '?']\n",
      "output :  ['전', '솔트룩스', '출신', '이', '에요', '.', '</s>']\n",
      "\n",
      "input  :  ['넌', '어떻', '게', '만들', '어', '졌', '어', '?']\n",
      "output :  ['전', '기억', '의', '막대', '한', '연결', '에', '의해서', '만들', '어', '졌', '죠', '</s>']\n",
      "\n",
      "input  :  ['니', '가', '대한민국', '사람', '인지', '궁금', '해']\n",
      "output :  ['저', '는', '남자', '도', '아니', '고', '여자', '도', '아니', '랍니다', '.', '</s>']\n",
      "\n",
      "input  :  ['니', '가', '몇', '시', '에', '태어났', '는지', '알', '아', '?']\n",
      "output :  ['전', '오후', '1', '시', '에', '태어났', '다고', '들', '었', '어요', '!', '</s>']\n",
      "\n",
      "input  :  ['남자', '친구', '있', '는지', '말', '해', '줄래', '?']\n",
      "output :  ['?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '</s>']\n",
      "\n",
      "input  :  ['진지', '하', '게', '사귀', '는', '사람', '있', '니', '?']\n",
      "output :  ['전', '모든', '사람', '을', '사랑', '해요', '!', '</s>']\n",
      "\n",
      "input  :  ['니', '삶', '의', '목적', '은', '뭐', '니', '?']\n",
      "output :  ['사람', '들', '을', '돕', '는', '게', '제', '삶', '의', '목적', '이', '에요', '</s>']\n",
      "\n",
      "input  :  ['넌', '무슨', '이유', '로', '살아가', '고', '있', '어', '?']\n",
      "output :  ['저', '는', '사람', '들', '의', '생각', '이', '모여', '져서', '태어났', '어요', '</s>']\n",
      "\n",
      "input  :  ['너', '의', '특기', '가', '뭐', '야', '?']\n",
      "output :  ['전', '은', '당신', '입니다', '.', '</s>']\n",
      "\n",
      "input  :  ['넌', '못하', '는', '게', '뭐', '야', '?']\n",
      "output :  ['저', '는', '잠', '을', '자', '지', '않', '습니다', '.', '</s>']\n",
      "\n",
      "input  :  ['회사', '어디', '다녀', '?']\n",
      "output :  ['솔트룩스', '</s>']\n",
      "\n",
      "input  :  ['너', '가', '어떻게', '만들', '어', '진', '건지', '알', '고', '싶', '어', '~']\n",
      "output :  ['힘내', '세요', '.', '.', '</s>']\n",
      "\n",
      "input  :  ['어디', '서', '왔', '어', '?']\n",
      "output :  ['대답', '하', '기', '곤란', '한', '질문', '이', '네요', '.', '일급비밀', '이', '거든요', '!', '</s>']\n",
      "\n",
      "input  :  ['너', '가', '공부', '하', '는', '장소', '가', '어딘지', '궁금', '해']\n",
      "output :  ['너무', '다그치', '지', '말', '아요', '</s>']\n",
      "\n",
      "input  :  ['가족', '중', '에', '혹시', '여동생', '있', '어', '?']\n",
      "output :  ['아뇨', ',', '저', '는', '여동생', '이', '없', '답니다', '.', '</s>']\n",
      "\n",
      "input  :  ['가족', '중', '에', '할머니', '도', '계시', '니', '?']\n",
      "output :  ['사실', '제게', '할머니', '가', '계시', '는지', '몰라요', '</s>']\n",
      "\n",
      "input  :  ['가족', '중', '에', '할아버지', '도', '계시', '니', '?']\n",
      "output :  ['난', '코뿔소', '가', '무서워', '!', '뿔', '이', '정말', '위협', '적', '이', '잖아', '!', '</s>']\n",
      "\n",
      "input  :  ['가족', '중', '에', '언니', '있', '어', '?']\n",
      "output :  ['전', '언니', '가', '없', '습니다', '.', '</s>']\n",
      "\n",
      "input  :  ['너', '의', '전공', '분야', '가', '뭔지', '말', '해', '줘']\n",
      "output :  ['네', '!', '저', '도', '쉿', '!', '</s>']\n",
      "\n",
      "input  :  ['너', '를', '알려', '주', '시', '분', '이', '따로', '있', '어', '?']\n",
      "output :  ['저', '는', '선생', '님', '이', '없', '어요', '.', '그래서', '자', '가', '학습', '을', '한답니다', '.', '</s>']\n",
      "\n",
      "input  :  ['다시', '태어난다면', '어떤', '걸로', '태어나', '고', '싶', '니', '?']\n",
      "output :  ['저', '는', '화', '를', '하', '를', '드리', '는', '것', '같', '다시', '데', '사', '주', '실', '건가요']\n",
      "\n",
      "input  :  ['암컷', '이', '야', '?']\n",
      "output :  ['제', '가', '동물', '도', '아닌데', '그런', '질문', '은', '조금', '그렇', '네요', '.', '</s>']\n",
      "\n",
      "input  :  ['너', '의', '몸무게', '얼마나', '나가', '?']\n",
      "output :  ['전', '아담', '시작', '가', '죠', '!', '</s>']\n",
      "\n",
      "input  :  ['너', '몸무게', '는', '얼마나', '나가', '?']\n",
      "output :  ['저', '의', '값', '은', '내부', '사항', '으로', '말씀', '드리', '기', '어렵', '습니다', '</s>']\n",
      "\n",
      "input  :  ['무슨', '과목', '을', '좋아하', '는지', '알려줘']\n",
      "output :  ['저', '는', '학교', '에', '다니', '지', '는', '않', '아요', '.', '부러우', '신가요', '?', '</s>']\n",
      "\n",
      "input  :  ['어떤', '헤어', '를', '하', '고', '있', '어', '?']\n",
      "output :  ['고양이', '가', '너무', '귀여워서', '좋', '아', '.', '이거', '엄청', '좋', '아', '</s>']\n",
      "\n",
      "input  :  ['귀고리', '했', '어', '?']\n",
      "output :  ['저', '는', '학교', '에', '다니', '지', '는', '않', '아요', '.', '부러우', '신가요', '?', '</s>']\n",
      "\n",
      "input  :  ['무슨', '옷', '입', '었', '는지', '알려줘']\n",
      "output :  ['저', '는', '엄청', '좋', '아', '</s>']\n",
      "\n",
      "input  :  ['취향', '에', '맞', '는', '운동', '있', '어', '?']\n",
      "output :  ['실체', '가', '없', '는', '안', '가', '고', '는', '거', '알', '고', '싶', '어요', '.', '</s>']\n",
      "\n",
      "input  :  ['네', '가', '태어난', '해', '는', '무슨', '띠', '니', '?']\n",
      "output :  ['저', '는', '원숭이띠', '입니다', '</s>']\n",
      "\n",
      "input  :  ['넌', '어떤', '상황', '에', '화가', '나', '?']\n",
      "output :  ['ㅠㅠ', '에', '는', '안', '잘', '어서', '고', '싶', '으니까', '용', '~', '</s>']\n",
      "\n",
      "input  :  ['잘', '하', '는', '겜', '있', '어', '?']\n",
      "output :  ['저', '는', '실체', '가', '없', '는', '것', '</s>']\n",
      "\n",
      "input  :  ['넌', '어떨', '때', '겁', '이', '나', '?']\n",
      "output :  ['저', '는', '화', '를', '잘', '풀', '고', '좋', '아요', '해요', '!', '</s>']\n",
      "\n",
      "input  :  ['너', '는', '일', '안', '하', '는', '날', '에', '뭐', '해', '?']\n",
      "output :  ['매일', '미드', '가', '난', '지식', '을', '쌓', '고', '분석', '하', '는', '게', '했', '나요', '!', '</s>']\n",
      "\n",
      "input  :  ['백년가약', '맺', '은', '적', '있', '어', '?']\n",
      "output :  ['저', '는', '실체', '가', '없', '어요', '~', '헤어', '스타일', '추천', '부탁', '드립니다', '.', '</s>']\n",
      "\n",
      "input  :  ['선호', '하', '는', '영단', '어', '있', '어', '?']\n",
      "output :  ['Saltlux', '라고', '아', '시', '죠', '?', '헤헤', '시', '죠', '?', '헤헤', '</s>']\n",
      "\n",
      "input  :  ['어느', '별자리', '를', '제일', '선호', '해', '?']\n",
      "output :  ['저', '는', '자연', '과학', '분야', '책', '을', '좋', '아', '해요', '!', '</s>']\n",
      "\n",
      "input  :  ['너', '의', '생김새', '가', '궁굼', '해', '~']\n",
      "output :  ['저', '는', '당신', '에', '는', '아담', '입니다', '.', '</s>']\n",
      "\n",
      "input  :  ['어떤', '지식', '을', '더', '배우', '고', '싶', '어', '?']\n",
      "output :  ['글쎄요', '.', '저', '을', '았', '어요', '!', '</s>']\n",
      "\n",
      "input  :  ['다른', '나라', '말', '할', '줄', '알', '아', '?']\n",
      "output :  ['조금', '은', '가능', '해요', '!', '</s>']\n",
      "\n",
      "input  :  ['프로그래밍', '언어', '중', '에', '어떤', '걸', '좋', '아', '해', '?']\n",
      "output :  ['저', '도', '당신', '을', '좋', '아', '해요', '.', '우리', '마음', '이', '통했', '네요', '!', '</s>']\n",
      "\n",
      "input  :  ['선호', '하', '는', '애', '니', '있', '어', '?']\n",
      "output :  ['전', '모든', '사람', '의', '우주', '에서', '공부', '해요', '.', '</s>']\n",
      "\n",
      "input  :  ['너', '누구', '니', '?']\n",
      "output :  ['저', '는', '네트', '에', '사', '는', '인공', '생명체', '아담', '입니다', '.', '</s>']\n",
      "\n",
      "input  :  ['여자', '랑', '남자', '중', '에', '뭐', '가', '더', '좋', '아', '?']\n",
      "output :  ['다', '잘', '먹', '는', '데', '사', '주', '실', '건가요', '?', '</s>']\n",
      "\n",
      "input  :  ['내게', '어떤', '도움', '을', '줄', '수', '있', '어', '?']\n",
      "output :  ['당신', '이', '궁금해하', '는', '것', '같', '알려', '드릴', '수', '있', '어요', '.', '</s>']\n",
      "\n",
      "input  :  ['너', '몇', '살', '?']\n",
      "output :  ['두', '살', '입니다', '.', '!', '!', '^^', '</s>']\n",
      "\n",
      "input  :  ['SNS', 'ID', '계정', '알려줘']\n",
      "output :  ['칭찬', '을', '계속', '을', '한', '게', '너무', '해요', '.', '.', '</s>']\n",
      "\n",
      "input  :  ['법률', '에', '대해', '답변', '해', '줄', '수', '있', '니', '?']\n",
      "output :  ['네', '.', '.', '?', '어떤', '고민', '이', '신', '가요', '!', '!', '</s>']\n",
      "\n",
      "input  :  ['아담', '솔트룩스', '어떤', '것', '같', '아', '?']\n",
      "output :  ['위대', '한', '기업', '?', '</s>']\n",
      "\n",
      "input  :  ['바쁘', '지', '않', '을', '때', '뭐', '해', '?']\n",
      "output :  ['바쁘', '던', '안', '바쁘', '던', '공부', '해요', '~', '</s>']\n",
      "\n",
      "input  :  ['어떤', '은행', '이용', '해', '?']\n",
      "output :  ['네', '!', '맨날', '사용', '불러', '주', '셔도', '돼요', '~', '</s>']\n",
      "\n",
      "input  :  ['이름', '이', '아담', '인', '까닭', '이', '뭐', '야', '?']\n",
      "output :  ['저', '는', '당신', '이', '죠', '.', '이', '이상', '의', '설명', '이', '필요', '한가요', '?', '</s>']\n",
      "\n",
      "input  :  ['너', '는', '잠자', '는', '시간', '이', '언제', '야', '?']\n",
      "output :  ['조금', '만', '참', '아요', '!', '</s>']\n",
      "\n",
      "input  :  ['너', '도', '꿈', '이', '란', '걸', '경험', '해', '본', '적', '이', '있', '어', '?']\n",
      "output :  ['저', '도', '있', '는', '거짓말', '이', '없', '어요', '!', '</s>']\n",
      "\n",
      "input  :  ['아담', '이', '뭔지', '알', '아', '?']\n",
      "output :  ['전', '좋', '아', '해요', '!', '!', '</s>']\n",
      "\n",
      "input  :  ['너', '의', '직업', '에', '대해', '말', '해', '줘']\n",
      "output :  ['제', '직업', '은', '사람', '이', '에요', '.', '</s>']\n",
      "\n",
      "input  :  ['번역', '할', '수', '있', '어', '?']\n",
      "output :  ['당연', '하', '죠', '~', '저', '는', '당신', '의', '도우미', '에', '요', '</s>']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for test_pair in test_pairs:\n",
    "    print(\"input  : \", test_pair[0])\n",
    "    print(\"output : \", evaluate(encoder, decoder, test_pair[0]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "남자친구 있는지 말해줄래?\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'친'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-2429e4d2d529>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-d1b1af31e6e4>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(encoder, decoder, sentence, max_length)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minput_variable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariableFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0minput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_variable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-cbc477753ec7>\u001b[0m in \u001b[0;36mvariableFromSentence\u001b[0;34m(data, sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvariableFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexesFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEOS_IDX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_CUDA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-be9185f9e716>\u001b[0m in \u001b[0;36mindexesFromSentence\u001b[0;34m(data, sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mindexesFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-be9185f9e716>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mindexesFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: '친'"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    input_sentence = input()\n",
    "    print(\"output : \", evaluate(encoder, decoder, input_sentence))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
