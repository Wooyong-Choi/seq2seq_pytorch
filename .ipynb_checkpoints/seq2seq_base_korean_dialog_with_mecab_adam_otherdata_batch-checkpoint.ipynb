{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import operator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from konlpy.tag import Twitter\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.0_2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "USE_CUDA = True\n",
    "GPU_ID = 3\n",
    "\n",
    "print(USE_CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SYMBOL = 4\n",
    "\n",
    "PAD_TOK = '<PAD>'\n",
    "SOS_TOK = '<SOS>'\n",
    "EOS_TOK = '<EOS>'\n",
    "UNK_TOK = '<UNK>'\n",
    "\n",
    "PAD_IDX = 0\n",
    "SOS_IDX = 1\n",
    "EOS_IDX = 2\n",
    "UNK_IDX = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_VOCAB_SIZE = 5000\n",
    "TGT_VOCAB_SIZE = 5000\n",
    "\n",
    "MAX_LENGTH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_FILENAME = 'dataset/korean_dialog/hangul_src.txt'\n",
    "TGT_FILENAME = 'dataset/korean_dialog/hangul_tgt.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {\n",
    "            SOS_IDX:SOS_TOK,\n",
    "            EOS_IDX:EOS_TOK,\n",
    "            PAD_IDX:PAD_TOK,\n",
    "            UNK_IDX:UNK_TOK\n",
    "        }\n",
    "        self.n_words = len(self.index2word)\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence:\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2count:\n",
    "            self.word2count[word] = 1\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "    def makeVocabDict(self, vocab_size):\n",
    "        sorted_vocab = sorted(self.word2count.items(), key=operator.itemgetter(1), reverse=True)[:vocab_size]\n",
    "        \n",
    "        sorted_i2w = {i+NUM_SYMBOL:sorted_vocab[i][0] for i in range(vocab_size)}\n",
    "        sorted_w2i = {sorted_vocab[i][0]:i for i in range(vocab_size)}\n",
    "        \n",
    "        self.index2word.update(sorted_i2w)\n",
    "        self.word2index.update(sorted_w2i)\n",
    "        \n",
    "        self.n_words = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    s = re.sub('[^가-힝0-9a-zA-Z\\\\s]', '', s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(src_fileName, tgt_fileName, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    src_lines = open(src_fileName, 'r', encoding='utf-8').readlines()\n",
    "    tgt_lines = open(tgt_fileName, 'r', encoding='utf-8').readlines()\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(src_lines[i][:-1]), normalizeString(tgt_lines[i][:-1])] for i in range(len(src_lines))]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_data = Data()\n",
    "        output_data = Data()\n",
    "    else:\n",
    "        input_data = Data()\n",
    "        output_data = Data()\n",
    "\n",
    "    print(\"Success!\")\n",
    "    \n",
    "    return input_data, output_data, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPair(p):\n",
    "    return len(p[0]) < MAX_LENGTH and \\\n",
    "        len(p[1]) < MAX_LENGTH\n",
    "    \n",
    "def filterPairs(pairs, tagger=Twitter()):\n",
    "    pairs = [[tagger.morphs(pair[0]), tagger.morphs(pair[1])] for pair in pairs]\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(src_fileName, tgt_fileName, reverse=False):\n",
    "    input_data, output_data, pairs = readData(src_fileName, tgt_fileName)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_data.addSentence(pair[0])\n",
    "        output_data.addSentence(pair[1])\n",
    "        \n",
    "    org_input_n_words = input_data.n_words\n",
    "    org_output_n_words = output_data.n_words\n",
    "        \n",
    "    input_data.makeVocabDict(SRC_VOCAB_SIZE)\n",
    "    output_data.makeVocabDict(TGT_VOCAB_SIZE)    \n",
    "    \n",
    "    print(\"Num of reduced words :\")\n",
    "    print(\"- Input data  :\", org_input_n_words - input_data.n_words)\n",
    "    print(\"- Output data :\", org_output_n_words - output_data.n_words)\n",
    "    \n",
    "    return input_data, output_data, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(data, sentence):\n",
    "    return [data.word2index[word] if word in data.word2index else UNK_IDX for word in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paddingSeqIndexes(seq):\n",
    "    pad_num = MAX_LENGTH - len(seq)\n",
    "    return seq + [PAD_IDX]*pad_num\n",
    "\n",
    "def variableFromSentence(data, sentence, isPadding=False):\n",
    "    indexes = indexesFromSentence(data, sentence)\n",
    "    indexes.append(EOS_IDX)\n",
    "    \n",
    "    if isPadding:\n",
    "        indexes = paddingSeqIndexes(indexes)\n",
    "    \n",
    "    #result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    result = Variable(torch.LongTensor(indexes))\n",
    "    if USE_CUDA:\n",
    "        return result.cuda(GPU_ID)\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variablesFromBatch(batch):\n",
    "    input_batch = []\n",
    "    target_batch = []\n",
    "    for pair in batch:\n",
    "        input_batch.append(variableFromSentence(input_data,pair[0], isPadding=True))\n",
    "        target_batch.append(variableFromSentence(output_data, pair[1], isPadding=True))\n",
    "        \n",
    "    if USE_CUDA:\n",
    "        return (torch.stack(input_batch, dim=0).cuda(GPU_ID), torch.stack(target_batch, dim=0).cuda(GPU_ID))\n",
    "    else:\n",
    "        return (torch.stack(input_batch, dim=0), torch.stack(target_batch, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Success!\n",
      "Read 92192 sentence pairs\n",
      "Trimmed to 87099 sentence pairs\n",
      "Counting words...\n",
      "Num of reduced words :\n",
      "- Input data  : 13799\n",
      "- Output data : 13806\n"
     ]
    }
   ],
   "source": [
    "input_data, output_data, pairs = prepareData(SRC_FILENAME, TGT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(pairs)*0.8)\n",
    "val_size = int(len(pairs)*0.1)\n",
    "test_size = int(len(pairs)*0.1)\n",
    "\n",
    "train_pairs = pairs[:train_size]\n",
    "val_pairs = pairs[train_size:train_size+val_size]\n",
    "test_pairs = pairs[train_size+val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBatch(data=train_pairs, batch_size=128):\n",
    "    num = len(data)\n",
    "    for idx in range(0, num, batch_size):\n",
    "        batch = data[idx:min(idx + batch_size, num)]\n",
    "        batch = sorted(batch, key=lambda x: len(x[0]), reverse=True)\n",
    "        batch_len = [len(d[0]) for d in batch]\n",
    "        yield (batch, batch_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = input_data.n_words  # Num of Words\n",
    "HIDDEN_SIZE = 256  # Embedding Dimension\n",
    "OUTPUT_SIZE = output_data.n_words\n",
    "\n",
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size, padding_idx=0)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input_seqs, input_lens, hidden):\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        packed = pack_padded_sequence(embedded, input_lens, batch_first=True)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, output_lengths = pad_packed_sequence(outputs, batch_first=True)\n",
    "        return outputs, hidden\n",
    "\n",
    "    def initHidden(self, cur_batch_size):\n",
    "        result = Variable(torch.zeros(self.n_layers, cur_batch_size, self.hidden_size))\n",
    "        if USE_CUDA:\n",
    "            return result.cuda(GPU_ID)\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "    def forward_step(self, input_var, hidden, cur_batch_size):\n",
    "        embedded  = self.embedding(input_var)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        output = self.out(output.view(-1, self.hidden_size))\n",
    "        output = self.softmax(output)\n",
    "        output = output.view(cur_batch_size, self.output_size, -1)\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def forward(self, inputs, hidden, cur_batch_size):        \n",
    "        decoder_outputs = []\n",
    "        sequence_symbols = []\n",
    "        #lengths = np.array([max_length] * batch_size)\n",
    "        \n",
    "        def decode(step, step_output):\n",
    "            decoder_outputs.append(step_output)\n",
    "            symbols = decoder_outputs[-1].topk(1)[1]\n",
    "            sequence_symbols.append(symbols)\n",
    "            return symbols\n",
    "        \n",
    "        decoder_input = inputs[:, 0].unsqueeze(1)\n",
    "        for di in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden = self.forward_step(decoder_input, hidden, cur_batch_size)\n",
    "            step_output = decoder_output.squeeze(2)\n",
    "            symbols = decode(di, step_output)\n",
    "            decoder_input = symbols\n",
    "        \n",
    "        sequence_symbols = torch.stack(sequence_symbols, dim=1).squeeze(2)\n",
    "        decoder_outputs = torch.stack(decoder_outputs, dim=0)\n",
    "        \n",
    "        return decoder_outputs, decoder_hidden, sequence_symbols\n",
    "\n",
    "    def initHidden(self, encoder_hidden):\n",
    "        result = Variable(torch.zeros(1, BATCH_SIZE, self.hidden_size))\n",
    "        if USE_CUDA:\n",
    "            return result.cuda(GPU_ID)\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, input_lengths, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "          criterion, max_length=MAX_LENGTH):\n",
    "    cur_batch_size = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden(cur_batch_size)\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda(GPU_ID) if USE_CUDA else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, input_lengths, encoder_hidden)\n",
    "\n",
    "    decoder_input = target_variable\n",
    "    decoder_input = decoder_input.cuda(GPU_ID) if USE_CUDA else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoder_outputs, decoder_hidden, generated_sequence = decoder(decoder_input, decoder_hidden, cur_batch_size)\n",
    "\n",
    "    for step, step_output in enumerate(decoder_outputs):\n",
    "        loss += criterion(step_output, target_variable[:, step])\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEpochs(encoder, decoder, n_epoch, print_every=1, plot_every=1, learning_rate=1e-3, w_decay=1e-5):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate, weight_decay=w_decay)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss(size_average=True)\n",
    "\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        for batch, batch_len in getBatch(batch_size=BATCH_SIZE):\n",
    "            input_variable, target_variable = variablesFromBatch(batch)\n",
    "    \n",
    "            loss = train(input_variable, batch_len, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "    \n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epoch),\n",
    "                                            epoch, epoch / n_epoch * 100, print_loss_avg))\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "        \n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleResponce(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=5):\n",
    "    input_variable = variableFromSentence(input_data, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden(1)\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda(GPU_ID) if USE_CUDA else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], [input_length], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "        \n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    score_board = [[[SOS_IDX], 0]]  #  list of [[sequence] and score]\n",
    "    \n",
    "    # with beam search\n",
    "    while len(score_board[0][0]) != max_length + 1:\n",
    "        # Select each candidate\n",
    "        for cur, cur_score in score_board: # [[sequence], score].\n",
    "            candidate = cur[-1]\n",
    "        \n",
    "            # Find beams\n",
    "            decoder_input = Variable(torch.LongTensor([[candidate]]))\n",
    "            decoder_input = decoder_input.cuda(GPU_ID) if USE_CUDA else decoder_input\n",
    "        \n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topVecs, topIdxs = decoder_output.data.topk(beam_size)\n",
    "        \n",
    "            for next, next_score in zip(topIdxs.tolist()[0], topVecs.tolist()[0]):\n",
    "                # Append beams to score board\n",
    "                score = cur_score + next_score  # log softmax\n",
    "                score_board.append([cur+[next], score])\n",
    "            \n",
    "        # select top 5\n",
    "        score_board = sorted(score_board, key=operator.itemgetter(1), reverse=True)[:5]\n",
    "\n",
    "    decoded_words = []\n",
    "    \n",
    "    for idx in score_board[0][0]:\n",
    "        if idx == EOS_IDX:\n",
    "            decoded_words.append(EOS_TOK)\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_data.index2word[idx])\n",
    "\n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleResponces(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = sampleResponces(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(INPUT_SIZE, HIDDEN_SIZE)\n",
    "decoder = DecoderRNN(HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "if USE_CUDA:\n",
    "    encoder.cuda(GPU_ID)\n",
    "    decoder.cuda(GPU_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 27s (- 91m 19s) (1 0%) 9793.2724\n",
      "0m 54s (- 90m 2s) (2 1%) 8679.7166\n",
      "1m 20s (- 88m 38s) (3 1%) 8550.7817\n",
      "1m 48s (- 88m 22s) (4 2%) 8450.9292\n",
      "2m 15s (- 88m 2s) (5 2%) 8365.5565\n",
      "2m 43s (- 87m 51s) (6 3%) 8296.2859\n",
      "3m 10s (- 87m 33s) (7 3%) 8238.3299\n",
      "3m 38s (- 87m 24s) (8 4%) 8181.3219\n",
      "4m 6s (- 87m 10s) (9 4%) 8132.8841\n",
      "4m 34s (- 86m 52s) (10 5%) 8080.6116\n",
      "5m 2s (- 86m 31s) (11 5%) 8037.0322\n",
      "5m 30s (- 86m 10s) (12 6%) 7991.5559\n",
      "5m 57s (- 85m 44s) (13 6%) 7946.0123\n",
      "6m 25s (- 85m 15s) (14 7%) 7902.1171\n",
      "6m 52s (- 84m 51s) (15 7%) 7861.7362\n",
      "7m 20s (- 84m 26s) (16 8%) 7812.6940\n",
      "7m 48s (- 83m 59s) (17 8%) 7768.6701\n",
      "8m 15s (- 83m 34s) (18 9%) 7723.9856\n",
      "8m 43s (- 83m 8s) (19 9%) 7679.9727\n",
      "9m 11s (- 82m 42s) (20 10%) 7641.3998\n",
      "9m 39s (- 82m 15s) (21 10%) 7596.3208\n",
      "10m 6s (- 81m 49s) (22 11%) 7555.4060\n",
      "10m 34s (- 81m 20s) (23 11%) 7523.8567\n",
      "11m 1s (- 80m 54s) (24 12%) 7493.0720\n",
      "11m 29s (- 80m 26s) (25 12%) 7487.1430\n",
      "11m 57s (- 80m 0s) (26 13%) 7469.8981\n",
      "12m 24s (- 79m 32s) (27 13%) 7439.5530\n",
      "12m 52s (- 79m 4s) (28 14%) 7405.1001\n",
      "13m 20s (- 78m 37s) (29 14%) 7359.2412\n",
      "13m 47s (- 78m 11s) (30 15%) 7313.7716\n",
      "14m 15s (- 77m 44s) (31 15%) 7270.3814\n",
      "14m 43s (- 77m 16s) (32 16%) 7229.1957\n",
      "15m 10s (- 76m 48s) (33 16%) 7194.4342\n",
      "15m 38s (- 76m 22s) (34 17%) 7157.6224\n",
      "16m 6s (- 75m 54s) (35 17%) 7126.5767\n",
      "16m 34s (- 75m 28s) (36 18%) 7095.4302\n",
      "17m 1s (- 75m 1s) (37 18%) 7064.7281\n",
      "17m 29s (- 74m 34s) (38 19%) 7043.0136\n",
      "17m 57s (- 74m 6s) (39 19%) 7019.8229\n",
      "18m 24s (- 73m 38s) (40 20%) 6994.1684\n",
      "18m 52s (- 73m 10s) (41 20%) 6970.6840\n",
      "19m 19s (- 72m 43s) (42 21%) 6947.4666\n",
      "19m 47s (- 72m 16s) (43 21%) 6920.2043\n",
      "20m 14s (- 71m 47s) (44 22%) 6895.3469\n",
      "20m 42s (- 71m 19s) (45 22%) 6873.7230\n",
      "21m 10s (- 70m 51s) (46 23%) 6849.1896\n",
      "21m 37s (- 70m 23s) (47 23%) 6825.9991\n",
      "22m 5s (- 69m 56s) (48 24%) 6799.0813\n",
      "22m 33s (- 69m 29s) (49 24%) 6776.7456\n",
      "23m 0s (- 69m 2s) (50 25%) 6746.3850\n",
      "23m 28s (- 68m 34s) (51 25%) 6724.7486\n",
      "23m 56s (- 68m 7s) (52 26%) 6701.4272\n",
      "24m 23s (- 67m 39s) (53 26%) 6675.0043\n",
      "24m 51s (- 67m 12s) (54 27%) 6654.9655\n",
      "25m 18s (- 66m 44s) (55 27%) 6633.1755\n",
      "25m 46s (- 66m 17s) (56 28%) 6613.5739\n",
      "26m 14s (- 65m 49s) (57 28%) 6593.1449\n",
      "26m 41s (- 65m 21s) (58 28%) 6571.7584\n",
      "27m 9s (- 64m 53s) (59 29%) 6550.0115\n",
      "27m 36s (- 64m 26s) (60 30%) 6530.9979\n",
      "28m 4s (- 63m 57s) (61 30%) 6513.1976\n",
      "28m 31s (- 63m 29s) (62 31%) 6495.1390\n",
      "28m 59s (- 63m 2s) (63 31%) 6478.7814\n",
      "29m 27s (- 62m 35s) (64 32%) 6465.0876\n",
      "29m 54s (- 62m 7s) (65 32%) 6441.0437\n",
      "30m 22s (- 61m 39s) (66 33%) 6424.4411\n",
      "30m 49s (- 61m 12s) (67 33%) 6408.2523\n",
      "31m 17s (- 60m 44s) (68 34%) 6391.5251\n",
      "31m 44s (- 60m 15s) (69 34%) 6374.4831\n",
      "32m 12s (- 59m 48s) (70 35%) 6360.0150\n",
      "32m 39s (- 59m 20s) (71 35%) 6343.8452\n",
      "33m 7s (- 58m 52s) (72 36%) 6331.1070\n",
      "33m 34s (- 58m 24s) (73 36%) 6319.4970\n",
      "34m 2s (- 57m 57s) (74 37%) 6301.7381\n",
      "34m 29s (- 57m 29s) (75 37%) 6289.8051\n",
      "34m 57s (- 57m 2s) (76 38%) 6270.7703\n",
      "35m 25s (- 56m 34s) (77 38%) 6260.3042\n",
      "35m 52s (- 56m 7s) (78 39%) 6247.7337\n",
      "36m 20s (- 55m 39s) (79 39%) 6232.0552\n",
      "36m 47s (- 55m 11s) (80 40%) 6218.7668\n",
      "37m 15s (- 54m 44s) (81 40%) 6208.7751\n",
      "37m 42s (- 54m 16s) (82 41%) 6196.0998\n",
      "38m 10s (- 53m 48s) (83 41%) 6183.5098\n",
      "38m 37s (- 53m 20s) (84 42%) 6176.5501\n",
      "39m 5s (- 52m 53s) (85 42%) 6162.2601\n",
      "39m 33s (- 52m 26s) (86 43%) 6151.3976\n",
      "40m 1s (- 51m 59s) (87 43%) 6139.8478\n",
      "40m 29s (- 51m 32s) (88 44%) 6131.4686\n",
      "40m 57s (- 51m 4s) (89 44%) 6122.0335\n",
      "41m 25s (- 50m 37s) (90 45%) 6115.2617\n",
      "41m 53s (- 50m 10s) (91 45%) 6101.7932\n",
      "42m 21s (- 49m 43s) (92 46%) 6089.1272\n",
      "42m 48s (- 49m 15s) (93 46%) 6083.2413\n",
      "43m 15s (- 48m 47s) (94 47%) 6072.2015\n",
      "43m 43s (- 48m 19s) (95 47%) 6068.5220\n",
      "44m 11s (- 47m 51s) (96 48%) 6056.8402\n",
      "44m 38s (- 47m 24s) (97 48%) 6049.4052\n",
      "45m 5s (- 46m 55s) (98 49%) 6040.5197\n",
      "45m 32s (- 46m 28s) (99 49%) 6028.0124\n",
      "45m 59s (- 45m 59s) (100 50%) 6020.6475\n",
      "46m 27s (- 45m 31s) (101 50%) 6008.4808\n",
      "46m 54s (- 45m 4s) (102 51%) 6002.8581\n",
      "47m 22s (- 44m 36s) (103 51%) 5993.4141\n",
      "47m 49s (- 44m 8s) (104 52%) 5992.2988\n",
      "48m 16s (- 43m 40s) (105 52%) 5983.9453\n",
      "48m 44s (- 43m 13s) (106 53%) 5979.4361\n",
      "49m 11s (- 42m 45s) (107 53%) 5967.4711\n",
      "49m 38s (- 42m 17s) (108 54%) 5958.0720\n",
      "50m 6s (- 41m 49s) (109 54%) 5952.5857\n",
      "50m 33s (- 41m 21s) (110 55%) 5948.4853\n",
      "51m 0s (- 40m 54s) (111 55%) 5940.5483\n",
      "51m 28s (- 40m 26s) (112 56%) 5937.2150\n",
      "51m 57s (- 39m 59s) (113 56%) 5930.1096\n",
      "52m 25s (- 39m 33s) (114 56%) 5922.9252\n",
      "52m 54s (- 39m 6s) (115 57%) 5915.0286\n",
      "53m 22s (- 38m 39s) (116 57%) 5907.9046\n",
      "53m 51s (- 38m 12s) (117 58%) 5897.5205\n",
      "54m 19s (- 37m 44s) (118 59%) 5894.3930\n",
      "54m 47s (- 37m 17s) (119 59%) 5893.4238\n",
      "55m 16s (- 36m 51s) (120 60%) 5892.1615\n",
      "55m 45s (- 36m 23s) (121 60%) 5879.2937\n",
      "56m 13s (- 35m 56s) (122 61%) 5872.9873\n",
      "56m 42s (- 35m 29s) (123 61%) 5868.3405\n",
      "57m 10s (- 35m 2s) (124 62%) 5871.8924\n",
      "57m 38s (- 34m 35s) (125 62%) 5863.3037\n",
      "58m 7s (- 34m 8s) (126 63%) 5856.6928\n",
      "58m 35s (- 33m 40s) (127 63%) 5853.5344\n",
      "59m 4s (- 33m 13s) (128 64%) 5849.0758\n",
      "59m 32s (- 32m 46s) (129 64%) 5844.2063\n",
      "60m 1s (- 32m 19s) (130 65%) 5837.2446\n",
      "60m 29s (- 31m 51s) (131 65%) 5832.6882\n",
      "60m 58s (- 31m 24s) (132 66%) 5828.6919\n",
      "61m 26s (- 30m 57s) (133 66%) 5818.1876\n",
      "61m 55s (- 30m 29s) (134 67%) 5811.0909\n",
      "62m 23s (- 30m 2s) (135 67%) 5806.9837\n",
      "62m 52s (- 29m 35s) (136 68%) 5804.7948\n",
      "63m 20s (- 29m 7s) (137 68%) 5803.1976\n",
      "63m 48s (- 28m 40s) (138 69%) 5798.4481\n",
      "64m 17s (- 28m 13s) (139 69%) 5796.1544\n",
      "64m 46s (- 27m 45s) (140 70%) 5791.2753\n",
      "65m 14s (- 27m 18s) (141 70%) 5788.5435\n",
      "65m 43s (- 26m 50s) (142 71%) 5785.5046\n",
      "66m 11s (- 26m 23s) (143 71%) 5779.7109\n",
      "66m 39s (- 25m 55s) (144 72%) 5768.4143\n",
      "67m 8s (- 25m 27s) (145 72%) 5766.7415\n",
      "67m 36s (- 25m 0s) (146 73%) 5761.7722\n",
      "68m 4s (- 24m 32s) (147 73%) 5757.5157\n",
      "68m 33s (- 24m 5s) (148 74%) 5755.9090\n",
      "69m 1s (- 23m 37s) (149 74%) 5748.0656\n",
      "69m 29s (- 23m 9s) (150 75%) 5747.9395\n",
      "69m 58s (- 22m 42s) (151 75%) 5744.4050\n",
      "70m 27s (- 22m 14s) (152 76%) 5745.6912\n",
      "70m 56s (- 21m 47s) (153 76%) 5740.7709\n",
      "71m 24s (- 21m 19s) (154 77%) 5732.0954\n",
      "71m 54s (- 20m 52s) (155 77%) 5730.5337\n",
      "72m 23s (- 20m 24s) (156 78%) 5733.5798\n",
      "72m 51s (- 19m 57s) (157 78%) 5725.5373\n",
      "73m 20s (- 19m 29s) (158 79%) 5714.7895\n",
      "73m 49s (- 19m 2s) (159 79%) 5716.8842\n",
      "74m 18s (- 18m 34s) (160 80%) 5719.5470\n",
      "74m 47s (- 18m 6s) (161 80%) 5719.8147\n",
      "75m 16s (- 17m 39s) (162 81%) 5714.6244\n",
      "75m 45s (- 17m 11s) (163 81%) 5707.4128\n",
      "76m 13s (- 16m 44s) (164 82%) 5705.0408\n",
      "76m 42s (- 16m 16s) (165 82%) 5699.2610\n",
      "77m 11s (- 15m 48s) (166 83%) 5691.3239\n",
      "77m 39s (- 15m 20s) (167 83%) 5685.8668\n",
      "78m 8s (- 14m 52s) (168 84%) 5676.9458\n",
      "78m 36s (- 14m 25s) (169 84%) 5681.8307\n",
      "79m 4s (- 13m 57s) (170 85%) 5679.9154\n",
      "79m 33s (- 13m 29s) (171 85%) 5678.7410\n",
      "80m 2s (- 13m 1s) (172 86%) 5674.6468\n",
      "80m 30s (- 12m 33s) (173 86%) 5668.7892\n",
      "80m 59s (- 12m 6s) (174 87%) 5666.7538\n",
      "81m 27s (- 11m 38s) (175 87%) 5668.6864\n",
      "81m 55s (- 11m 10s) (176 88%) 5663.6798\n",
      "82m 24s (- 10m 42s) (177 88%) 5659.9994\n",
      "82m 52s (- 10m 14s) (178 89%) 5653.9087\n",
      "83m 20s (- 9m 46s) (179 89%) 5653.3474\n",
      "83m 48s (- 9m 18s) (180 90%) 5657.1002\n",
      "84m 17s (- 8m 50s) (181 90%) 5656.0637\n",
      "84m 45s (- 8m 22s) (182 91%) 5643.6141\n",
      "85m 14s (- 7m 55s) (183 91%) 5646.1782\n",
      "85m 42s (- 7m 27s) (184 92%) 5640.4060\n",
      "86m 11s (- 6m 59s) (185 92%) 5636.3520\n",
      "86m 39s (- 6m 31s) (186 93%) 5637.1758\n",
      "87m 8s (- 6m 3s) (187 93%) 5634.9642\n",
      "87m 37s (- 5m 35s) (188 94%) 5634.4040\n",
      "88m 5s (- 5m 7s) (189 94%) 5628.7408\n",
      "88m 33s (- 4m 39s) (190 95%) 5622.7529\n",
      "89m 2s (- 4m 11s) (191 95%) 5617.7126\n",
      "89m 30s (- 3m 43s) (192 96%) 5615.6853\n",
      "90m 0s (- 3m 15s) (193 96%) 5622.0343\n",
      "90m 28s (- 2m 47s) (194 97%) 5623.1066\n",
      "90m 57s (- 2m 19s) (195 97%) 5611.9145\n",
      "91m 26s (- 1m 51s) (196 98%) 5614.1278\n"
     ]
    }
   ],
   "source": [
    "trainEpochs(encoder, decoder, NUM_EPOCH, print_every=1, plot_every=1, learning_rate=1e-3, w_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), 'encoder.model')\n",
    "torch.save(decoder.state_dict(), 'decoder.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "\n",
    "def evalModel(encoder, decoder):\n",
    "    \n",
    "    loss = 0\n",
    "\n",
    "    criterion = nn.NLLLoss(size_average=True)\n",
    "\n",
    "    for batch, batch_len in getBatch(data=test_pairs, batch_size=BATCH_SIZE):\n",
    "        input_variable, target_variable = variablesFromBatch(batch)\n",
    "    \n",
    "        cur_batch_size = input_variable.size()[0]\n",
    "        encoder_hidden = encoder.initHidden(cur_batch_size)\n",
    "        \n",
    "        target_length = target_variable.size()[0]\n",
    "        \n",
    "        encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n",
    "        encoder_outputs = encoder_outputs.cuda(GPU_ID) if USE_CUDA else encoder_outputs\n",
    "        \n",
    "        encoder_outputs, encoder_hidden = encoder(input_variable, batch_len, encoder_hidden)\n",
    "        \n",
    "        decoder_input = target_variable\n",
    "        decoder_input = decoder_input.cuda(GPU_ID) if USE_CUDA else decoder_input\n",
    "        \n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs, decoder_hidden, generated_sequence = decoder(decoder_input, decoder_hidden, cur_batch_size)\n",
    "        \n",
    "        for step, step_output in enumerate(decoder_outputs):\n",
    "            loss += criterion(step_output, target_variable[:, step]).data[0]/cur_batch_size\n",
    "        \n",
    "    print('loss = ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalModel(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for test_pair in getBatch(data=train_pairs, batch_size=128):\n",
    "    print(\"input  : \", test_pair[0])\n",
    "    print(\"output : \", evaluate(encoder, decoder, test_pair[0]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    input_sentence = input()\n",
    "    print(\"output : \", evaluate(encoder, decoder, input_sentence))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
